{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = pd.read_csv(\"Dataset.csv\")\n",
    "data = data.drop('Name', axis = 1)\n",
    "\n",
    "x = data.drop('Emotion', axis = 1)\n",
    "y = data['Emotion']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "xRescaled = scaler.fit_transform(x)\n",
    "x = pd.DataFrame(data = xRescaled, columns = x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "dataTrain, dataTest, classTrain, classTest = train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "mlp = MLPClassifier(solver = 'sgd', random_state = 123, activation = 'logistic', learning_rate_init = 0.3, batch_size = 100, \\\n",
    "                    hidden_layer_sizes = (100,50,), max_iter = 1000)\n",
    "\n",
    "mlp.fit(dataTrain, classTrain)\n",
    "\n",
    "predTrain = mlp.predict(dataTrain)\n",
    "predTest = mlp.predict(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Training Set:\n",
      "[[[1002    0]\n",
      "  [  14  136]]\n",
      "\n",
      " [[ 977   17]\n",
      "  [   4  154]]\n",
      "\n",
      " [[ 989   10]\n",
      "  [   3  150]]\n",
      "\n",
      " [[1006    3]\n",
      "  [   2  141]]\n",
      "\n",
      " [[ 983    9]\n",
      "  [   2  158]]\n",
      "\n",
      " [[1074    5]\n",
      "  [  15   58]]\n",
      "\n",
      " [[ 990    7]\n",
      "  [   6  149]]\n",
      "\n",
      " [[ 990    2]\n",
      "  [   7  153]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "print(\"Confusion Matrix for Training Set:\")\n",
    "print(multilabel_confusion_matrix(classTrain, predTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Test Set:\n",
      "[[[240   6]\n",
      "  [ 18  24]]\n",
      "\n",
      " [[234  20]\n",
      "  [  9  25]]\n",
      "\n",
      " [[231  18]\n",
      "  [ 19  20]]\n",
      "\n",
      " [[229  10]\n",
      "  [ 21  28]]\n",
      "\n",
      " [[229  27]\n",
      "  [  5  27]]\n",
      "\n",
      " [[258   7]\n",
      "  [ 18   5]]\n",
      "\n",
      " [[231  20]\n",
      "  [ 21  16]]\n",
      "\n",
      " [[240  16]\n",
      "  [ 13  19]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix for Test Set:\")\n",
    "print(multilabel_confusion_matrix(classTest, predTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9539930555555556\n",
      "Testing Accuracy:  0.5694444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Training Accuracy: \", accuracy_score(classTrain, predTrain))\n",
    "print(\"Testing Accuracy: \", accuracy_score(classTest, predTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       1.00      0.91      0.95       150\n",
      "        CALM       0.90      0.97      0.94       158\n",
      "     DISGUST       0.94      0.98      0.96       153\n",
      "     FEARFUL       0.98      0.99      0.98       143\n",
      "       HAPPY       0.95      0.99      0.97       160\n",
      "     NEUTRAL       0.92      0.79      0.85        73\n",
      "         SAD       0.96      0.96      0.96       155\n",
      "   SURPRISED       0.99      0.96      0.97       160\n",
      "\n",
      "    accuracy                           0.95      1152\n",
      "   macro avg       0.95      0.94      0.95      1152\n",
      "weighted avg       0.96      0.95      0.95      1152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Classification Report for Training Set: \")\n",
    "print(classification_report(classTrain, predTrain, zero_division = 0, target_names = mlp.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Testing Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       0.80      0.57      0.67        42\n",
      "        CALM       0.56      0.74      0.63        34\n",
      "     DISGUST       0.53      0.51      0.52        39\n",
      "     FEARFUL       0.74      0.57      0.64        49\n",
      "       HAPPY       0.50      0.84      0.63        32\n",
      "     NEUTRAL       0.42      0.22      0.29        23\n",
      "         SAD       0.44      0.43      0.44        37\n",
      "   SURPRISED       0.54      0.59      0.57        32\n",
      "\n",
      "    accuracy                           0.57       288\n",
      "   macro avg       0.57      0.56      0.55       288\n",
      "weighted avg       0.59      0.57      0.56       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Testing Set: \")\n",
    "print(classification_report(classTest, predTest, zero_division = 0, target_names = mlp.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
